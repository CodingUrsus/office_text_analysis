---
title: "The_Office_Text_Analysis"
author: "Austin"
date: "8/31/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r libraries, include=FALSE}

library(tidyverse)
library(readxl)
library(tidytext)
library(textdata)
library(tidyr)
library(igraph)
library(ggplot2)
library(ggraph)

initial_data <- read_excel("/home/hammera/office_data/the-office-lines.xlsx")

mod_data <- initial_data %>% 
  filter(deleted == "FALSE") %>% 
  mutate(actions = str_extract_all(line_text, "\\[.*?\\]"),
         line_text_mod = str_trim(str_replace_all(line_text, "\\[.*?\\]", ""))) %>% 
  mutate_at(vars(line_text_mod), funs(str_replace_all(., "���","'"))) %>% 
  mutate_at(vars(speaker), funs(tolower)) %>% 
  mutate_at(vars(speaker), funs(str_trim(str_replace_all(., "\\[.*?\\]", "")))) %>% 
  mutate_at(vars(speaker), funs(str_replace_all(., "micheal|michel|michae$", "michael")))


## Need to render each of the words into its own line
text_df_original <- mod_data %>% unnest_tokens(word, line_text_mod)

## Words which are used most often during the show, but first get rid of common words. Conveniently, these are stored in the data(stop_words) and can be removed using anti-join

data(stop_words)

text_df <- text_df_original %>% anti_join(stop_words)

array_of_words <- text_df %>% count(word, sort=TRUE)


## How many times is michael's name used after season 7? 13
text_df %>% subset(text_df$season > 7) %>% count(word=="michael", sort=TRUE)

## gutenbergr is a nice package for looking at data from a bunch of open source books

frequency <- text_df %>% group_by(season)

nrc_joy <- get_sentiments("nrc") %>% filter(sentiment == "joy")
nrc_sadness <- get_sentiments("nrc") %>% filter(sentiment=="sadness")
nrc_anger <- get_sentiments("nrc") %>% filter(sentiment=="anger")
nrc_fear <- get_sentiments("nrc") %>% filter(sentiment=="fear")


## What are the words typically associated with joy which michael most often uses? Recall that analyses like this don't take into account sarcasm because it considers the individual words as unigrams
michael_happy <- text_df %>%
  filter(speaker == "michael") %>%
  inner_join(nrc_joy) %>%
  count(word, sort=TRUE)

## What about Pan? I mean, Pam?
pam_happy <- text_df %>%
  filter(speaker == "pam") %>%
  inner_join(nrc_joy) %>%
  count(word, sort=TRUE)


## "That's what she said"





```


```{r michael_sentiment_exploration, include=FALSE}

text_df_full <- text_df %>%
  group_by(season) %>%
  mutate(word_number= row_number())

plot_sentiment_df <- text_df_full %>%
  inner_join(get_sentiments("bing")) %>%
  count(season, index = word_number %/% 300, sentiment) %>%
  spread(sentiment, n, fill=0) %>%
  mutate(total_sent=(positive-negative))
  
sent_by_season <- ggplot(data=plot_sentiment_df, mapping=aes(x=index, y=total_sent, fill=as.factor(season))) + geom_col() + facet_grid(rows=vars(season)) + ylab(label="Sentiment Score")

michael_sentiment_df <- subset(text_df, text_df$speaker=="michael") %>%
  inner_join(get_sentiments("afinn")) %>%
  group_by(season) %>%
  mutate(line_number=row_number())%>%
  ungroup() %>%
  mutate(index=line_number %/% 10) %>%
  group_by(index, season) %>%
  summarise(sentiment=sum(value))

michael_sentiment <- ggplot(data=michael_sentiment_df, aes(x=index, y=sentiment, fill=as.factor(season))) + geom_col() + facet_grid(rows=vars(season))
```

##SENTIMENT BY SEASON

The first plot shows the overall sentiment using the "bing" index for all seasons. Consider breaking it up by episode to see if there's a preserved structure.

The second plot shows summed sentiment scores for Michael using the "afinn" index across seasons.

```{r chunk_2, echo=FALSE}
sent_by_season
michael_sentiment
```


```{r chunk_3, echo=FALSE}
michaels_words <- text_df %>%
  subset(speaker=="michael") %>%
  ##group_by(season) %>%
  count(word, sort=TRUE) %>%
  inner_join(get_sentiments("bing"))

michaels_top_words <- michaels_words %>%
  group_by(sentiment) %>%
  top_n(10) %>%
  ungroup()

bigram_df <- mod_data %>%
  unnest_tokens(bigram, line_text_mod, token="ngrams", n=2, collapse=FALSE)
  

bigram_counts <- bigram_df %>%
  count(bigram, sort=TRUE) %>%
  filter(!is.na(bigram)) %>%
  separate(bigram, c("word_1", "word_2"), sep=" ") %>%
  filter(!word_1 %in% stop_words$word) %>%
  filter(!word_2 %in% stop_words$word)

bigrams_united <- bigram_counts %>%
  unite(bigram, word_1, word_2, sep=" ")

## Not extremely interesting, especially after removing the common stop words (consider that most three word phrases are going to depend on stop words to some degree)
trigram_df <- mod_data %>%
  unnest_tokens(trigram, line_text_mod, token="ngrams", n=3, collapse = FALSE) %>%
  count(trigram, sort=TRUE) %>%
  separate(trigram, c("word_1", "word_2", "word_3"), sep=" ") %>%
  filter(!word_1 %in% stop_words$word) %>%
  filter(!word_2 %in% stop_words$word)

bigram_full_names <- bigram_counts %>%
  filter(word_1 %in% unique(mod_data$speaker))

## Out of curiosity, and kind of out of character, in descending order which characters speak the most in the show?
characters_words <- text_df_original %>%
  group_by(speaker) %>%
  count(word, sort=TRUE) %>%
  summarise(char_sum = sum(n)) %>%
  ungroup() %>%
  arrange(desc(char_sum)) %>%
  top_n(20)

character_words_plot <- characters_words %>%
  ggplot(mapping=aes(x=factor(speaker, levels=c(speaker)), y=char_sum, fill=speaker)) +
  geom_bar(stat="identity") +
  xlab(label="Speaker") +
  ylab(label="# of Words Spoken") +
  coord_flip() +
  theme(legend.position = "none")
  





## Might be interesting to get a count for the number of episodes that each character is in, pair that df with a df of the number of words that they uniquely speak, then perform a regression or correlation analysis

```

```{r word_frequency, include=FALSE}
all_words <- mod_data %>%
  unnest_tokens(word, line_text_mod) %>%
  count(season, word, sort=TRUE) %>%
  anti_join(stop_words)

count_phrase <- function(df_to_check, search_phrase){
  lines_with_phrase <- df_to_check %>%
##    filter(speaker==character_who_said_it) %>%
    filter(grepl(search_phrase, line_text_mod))
  return(lines_with_phrase)
}

lower_no_punct_df <- mod_data %>%
  mutate_at(c("line_text_mod"), funs(tolower)) %>%
  mutate_at(c("line_text_mod"), funs(str_replace_all(., "[:punct:]", "")))


##Another curious Michael Scott-ism, he mentions it a ton
michael_twss <- count_phrase(lower_no_punct_df, "you know what") %>%
  filter(speaker=="michael") %>%
  group_by(season) %>%
  count()

ggplot(michael_twss, mapping=aes(x=as.factor(season), y=n)) + geom_bar(stat="identity")

character_graph_df <- bigram_df %>%
  count(bigram) %>%
  separate(bigram, c("word_1", "word_2"), sep=" ") %>%
  filter(word_2 %in% c("michael", "dwight", "jim", "andy", "pam", "angela")) %>%
  filter(n>1) %>%
  filter(!word_1 %in% stop_words$word)

character_graph <- character_graph_df %>%
  graph_from_data_frame()

c_graph <- ggraph(character_graph, layout = "fr") +
  geom_edge_link() +
  geom_node_point() +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1)

```

This graph shows the names of characters linked to specific words, and shows the relationship that is shared between specific words and characters. For instance, looking at the links between michael and dwight, there is a link to the word dammit. 

```{r chunk_5, echo=FALSE}
c_graph
character_words_plot


```
How many episodes does each character speak in?
```{r chunk_6, echo=FALSE}
character_episodes_df <- mod_data %>%
  group_by(speaker) %>%
  group_by(season, episode) %>%
  unique() %>%
  count()


michael_episodes_df <- mod_data %>%
  filter(speaker=="michael") %>%
  group_by(season, episode) %>%
  summarise(count=n()) %>%
  count()

speaker_episodes_df <- mod_data %>%
  group_by(speaker, season, episode) %>%
  summarise() %>%
  ungroup(speaker, season, episode) %>%
  count(speaker) %>%
  top_n(50) %>%
  arrange(desc(n)) %>%
  subset(!speaker %in% c("all", "guy", "woman", "group", "everyone")) %>%
  mutate(percent_episodes = (n/186)*100)

speaker_words <- text_df_original %>%
  group_by(speaker) %>%
  count(word, sort=TRUE) %>%
  summarise(char_sum = sum(n)) %>%
  ungroup() %>%
  arrange(desc(char_sum)) %>%
  top_n(40)

words_and_episodes <- inner_join(speaker_words, speaker_episodes_df)

ggplot(data=words_and_episodes, mapping=aes(x=n, y=char_sum, label=speaker)) + 
  geom_smooth(method=c("lm")) + 
  geom_point(aes(color=char_sum)) +
  geom_text(aes(label=speaker),hjust=0, vjust=0)


```

```{r chunk_7, echo=FALSE}




```

```{r chunk_8, echo=FALSE}




```

```{r chunk_9, echo=FALSE}




```

```{r chunk_10, echo=FALSE}




```






